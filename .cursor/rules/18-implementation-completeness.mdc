---
description: Anti-fake implementation guardrails to prevent incomplete, stubbed, or fake implementations
globs:
alwaysApply: true
---

# Implementation Completeness Guardrails

## Core Principle

**No incomplete, stubbed, or fake implementations in production code.** All business logic must be fully implemented with proper error handling and real integrations.

## Implementation Quality Detection

### PLACEHOLDER Detection

**Automated Detection Patterns:**
```bash
# Find all placeholder implementations
rg -n "PLACEHOLDER|TODO|MOCK_DATA|FIXME|HACK" src/
rg -n "throw new Error.*not implemented" src/
rg -n "return.*mock|fake|dummy" src/
rg -n "console\.log.*placeholder" src/
```

**Integration with Existing Tooling:**
```bash
# Use the existing todo_analyzer.py for comprehensive detection
python scripts/v3/analysis/todo_analyzer.py --root . --min-confidence 0.7 --ci-mode

# Analyze staged files with dependency resolution
python scripts/v3/analysis/todo_analyzer.py --staged-only --min-confidence 0.7

# Focus on v3 implementation only
python scripts/v3/analysis/todo_analyzer.py --v3-only --min-confidence 0.8
```

**Required Tagging:**
```typescript
// PLACEHOLDER: Real payment processing not implemented
function processPayment(amount: number): Promise<PaymentResult> {
  throw new Error("PLACEHOLDER: Payment processing not implemented");
}

// TODO: Implement actual tax calculation
function calculateTax(amount: number): number {
  if (process.env.NODE_ENV === 'production') {
    throw new Error("TODO: Tax calculation must be implemented before production");
  }
  return amount * 0.1; // Mock calculation
}

// MOCK DATA: Remove before production
const mockUsers = [
  { id: 1, name: "John Doe", email: "john@example.com" }
];
```

### Stub Implementation Prevention

**Forbidden Patterns:**
```typescript
// ‚ùå BAD: Silent stub implementation
function getUserData(id: string) {
  return { id, name: "Mock User" }; // No indication this is fake
}

// ‚ùå BAD: Console.log stub
function processOrder(order: Order) {
  console.log("Processing order:", order); // Not real implementation
  return { success: true };
}

// ‚ùå BAD: Empty implementation
function calculateTotal(items: Item[]) {
  // Implementation coming soon
  return 0;
}
```

**Required Patterns:**
```typescript
// ‚úÖ GOOD: Explicit placeholder with error
function getUserData(id: string) {
  // PLACEHOLDER: Real user data fetching not implemented
  throw new Error("PLACEHOLDER: getUserData not implemented");
}

// ‚úÖ GOOD: Proper implementation
function processOrder(order: Order) {
  const total = calculateTotal(order.items);
  const tax = calculateTax(total);
  return { success: true, total, tax };
}
```

## Fake Persistence Detection

### Database Mock Detection

**Forbidden Patterns:**
```typescript
// ‚ùå BAD: In-memory "database"
class UserRepository {
  private users: User[] = []; // Not real persistence
  
  async save(user: User) {
    this.users.push(user); // Fake persistence
  }
}

// ‚ùå BAD: Mock database operations
async function createUser(userData: CreateUserRequest) {
  // Mock database call
  return { id: Math.random(), ...userData };
}
```

**Required Patterns:**
```typescript
// ‚úÖ GOOD: Real database implementation
class UserRepository {
  constructor(private db: Database) {}
  
  async save(user: User) {
    const result = await this.db.query(
      'INSERT INTO users (name, email) VALUES ($1, $2) RETURNING *',
      [user.name, user.email]
    );
    return result.rows[0];
  }
}
```

### API Mock Detection

**Forbidden Patterns:**
```typescript
// ‚ùå BAD: Fake API responses
async function fetchUserData(id: string) {
  // Mock API response
  return { id, name: "Mock User", email: "mock@example.com" };
}

// ‚ùå BAD: Hardcoded responses
async function getWeatherData(city: string) {
  return { city, temperature: 72, condition: "sunny" }; // Fake data
}
```

**Required Patterns:**
```typescript
// ‚úÖ GOOD: Real API implementation
async function fetchUserData(id: string) {
  const response = await fetch(`/api/users/${id}`, {
    headers: { 'Authorization': `Bearer ${token}` }
  });
  
  if (!response.ok) {
    throw new Error(`Failed to fetch user: ${response.statusText}`);
  }
  
  return await response.json();
}
```

## Business Logic Completeness

### Core Business Functions

**Must be fully implemented:**
- Authentication and authorization
- Data validation and sanitization
- Business rule enforcement
- Error handling and recovery
- Audit logging and monitoring

**Implementation Requirements:**
```typescript
// ‚úÖ GOOD: Complete business logic
class OrderService {
  async processOrder(order: Order): Promise<OrderResult> {
    // Validate input
    if (!order.items || order.items.length === 0) {
      throw new ValidationError("Order must contain items");
    }
    
    // Check inventory
    const inventoryCheck = await this.inventoryService.checkAvailability(order.items);
    if (!inventoryCheck.available) {
      throw new InsufficientInventoryError(inventoryCheck.unavailableItems);
    }
    
    // Calculate pricing
    const pricing = await this.pricingService.calculateOrder(order);
    
    // Process payment
    const payment = await this.paymentService.processPayment({
      amount: pricing.total,
      method: order.paymentMethod
    });
    
    // Create order record
    const orderRecord = await this.orderRepository.create({
      ...order,
      total: pricing.total,
      paymentId: payment.id,
      status: 'confirmed'
    });
    
    // Send confirmation
    await this.notificationService.sendOrderConfirmation(orderRecord);
    
    return {
      orderId: orderRecord.id,
      total: pricing.total,
      estimatedDelivery: pricing.estimatedDelivery
    };
  }
}
```

## Quality Gates for Implementation

### Pre-Production Checks

**Automated Verification:**
```bash
# Check for incomplete implementations
npm run check:completeness
# - Scan for PLACEHOLDER/TODO/MOCK_DATA
# - Verify all business logic is implemented
# - Check for real database connections
# - Validate API integrations

# Check for fake persistence
npm run check:persistence
# - Verify database connections are real
# - Check for in-memory storage patterns
# - Validate migration scripts exist
```

### Implementation Completeness Matrix

| Component | Real DB | Real APIs | Error Handling | Validation | Logging |
|-----------|---------|-----------|----------------|------------|---------|
| **Auth** | ‚úÖ Required | ‚úÖ Required | ‚úÖ Required | ‚úÖ Required | ‚úÖ Required |
| **Billing** | ‚úÖ Required | ‚úÖ Required | ‚úÖ Required | ‚úÖ Required | ‚úÖ Required |
| **Data Processing** | ‚úÖ Required | ‚úÖ Required | ‚úÖ Required | ‚úÖ Required | ‚úÖ Required |
| **UI Components** | N/A | ‚úÖ Required | ‚úÖ Required | ‚úÖ Required | Optional |
| **Utilities** | N/A | ‚úÖ Required | ‚úÖ Required | ‚úÖ Required | Optional |

## Advanced Detection Patterns

### Leveraging Existing todo_analyzer.py

**High-Confidence Hidden TODO Patterns:**
```python
# From todo_analyzer.py - these patterns are already detected
high_confidence_patterns = {
    'incomplete_implementation': [
        r'\bnot\s+yet\s+implemented\b',
        r'\bmissing\s+implementation\b',
        r'\bincomplete\s+implementation\b',
        r'\bpartial\s+implementation\b',
        r'\bunimplemented\b',
        r'\bnot\s+done\b',
        r'\bpending\s+implementation\b',
        r'\bto\s+be\s+implemented\b',
        r'\bwill\s+be\s+implemented\b',
    ],
    
    'placeholder_code': [
        r'\bplaceholder\s+code\b',
        r'\bplaceholder\s+implementation\b',
        r'\bstub\s+implementation\b',
        r'\bdummy\s+implementation\b',
        r'\bfake\s+implementation\b',
        r'\bsimplified\s+.*?\s+implementation\b',
        r'\bfor\s+now\b.*?(just|simply|only)\s+(concatenate|return|use)',
    ],
    
    'temporary_solutions': [
        r'\btemporary\s+solution\b',
        r'\btemporary\s+fix\b',
        r'\bquick\s+fix\b',
        r'\bworkaround\b',
        r'\bhack\b.*?(fix|solution)',
    ],
    
    'hardcoded_values': [
        r'\bhardcoded\s+value\b',
        r'\bmagic\s+number\b',
        r'\bmagic\s+string\b',
        r'\bconstant\s+value\b.*?(replace|change|make\s+configurable)',
    ],
    
    'future_improvements': [
        r'\bin\s+production\b.*?(implement|add|fix)',
        r'\bin\s+a\s+real\s+implementation\b',
        r'\beventually\b.*?(implement|add|fix)',
        r'\bshould\s+be\b.*?(implemented|added|fixed)',
        r'\bwould\s+be\b.*?(implemented|added|fixed)',
    ],
}
```

**Code Stub Detection:**
```python
# Language-specific stub patterns already implemented
code_stub_patterns = {
    'python': {
        'function_stub': re.compile(r'^\s*def\s+\w+\(.*\):'),
        'pass_stmt': re.compile(r'^\s*pass\s*$'),
        'ellipsis_stmt': re.compile(r'^\s*\.\.\.\s*$'),
        'raise_not_impl': re.compile(r'^\s*raise\s+NotImplementedError'),
    },
    'javascript': {
        'function_stub': re.compile(r'^\s*(async\s+)?function\s+\w+\(.*\)\s*{'),
        'throw_not_impl': re.compile(r"^\s*throw\s+new\s+Error\((\"|')(TODO|Not\s+Implemented)"),
        'return_todo': re.compile(r"^\s*return\s+(null|undefined);\s*//\s*TODO"),
    },
    'typescript': {
        'function_stub': re.compile(r'^\s*(async\s+)?function\s+\w+\(.*\)\s*{'),
        'throw_not_impl': re.compile(r"^\s*throw\s+new\s+Error\((\"|')(TODO|Not\s+Implemented)"),
        'return_todo': re.compile(r"^\s*return\s+(null|undefined);\s*//\s*TODO"),
    },
}
```

## Enforcement Mechanisms

### Pre-Commit Hooks

```bash
# Use existing todo_analyzer.py for comprehensive detection
check-implementation-completeness() {
  echo "üîç Running comprehensive TODO analysis..."
  
  # Run todo_analyzer.py in CI mode
  python scripts/v3/analysis/todo_analyzer.py --staged-only --min-confidence 0.7 --ci-mode
  
  if [ $? -ne 0 ]; then
    echo "‚ùå Hidden TODOs detected in staged files"
    echo "Run: python scripts/v3/analysis/todo_analyzer.py --staged-only --min-confidence 0.7"
    echo "to see detailed analysis"
    exit 1
  fi
  
  echo "‚úÖ No hidden TODOs found in staged files"
}

# Legacy simple check (fallback)
check-simple-placeholders() {
  local placeholders=$(git diff --cached | grep -E "PLACEHOLDER|TODO|MOCK_DATA" | wc -l)
  if [ "$placeholders" -gt 0 ]; then
    echo "‚ùå Found $placeholders placeholder implementations"
    echo "All business logic must be fully implemented"
    exit 1
  fi
}
```

### CI/CD Integration

```yaml
# Implementation completeness checks using existing todo_analyzer.py
- name: Check Implementation Completeness
  run: |
    echo "üîç Running comprehensive hidden TODO analysis..."
    
    # Run todo_analyzer.py with high confidence threshold
    python scripts/v3/analysis/todo_analyzer.py \
      --root . \
      --min-confidence 0.8 \
      --ci-mode \
      --output-json todo-analysis-results.json
    
    if [ $? -ne 0 ]; then
      echo "‚ùå Hidden TODOs detected - blocking CI/CD"
      echo "Review todo-analysis-results.json for details"
      exit 1
    fi
    
    echo "‚úÖ No high-confidence hidden TODOs found"

- name: Analyze Staged Files (Pre-commit)
  run: |
    # For pre-commit hooks, analyze only staged files
    python scripts/v3/analysis/todo_analyzer.py \
      --staged-only \
      --min-confidence 0.7 \
      --ci-mode \
      --disable-dependency-resolution
    
    if [ $? -ne 0 ]; then
      echo "‚ùå Hidden TODOs in staged files"
      exit 1
    fi

- name: Generate TODO Report
  run: |
    # Generate comprehensive report for review
    python scripts/v3/analysis/todo_analyzer.py \
      --root . \
      --min-confidence 0.6 \
      --output-md hidden-todos-report.md \
      --output-json hidden-todos-analysis.json
    
    # Upload artifacts for review
    echo "üìä TODO analysis report generated"
```

## Testing Requirements

### Implementation Testing

**Must test real implementations:**
```typescript
// ‚úÖ GOOD: Test real database operations
describe("UserRepository", () => {
  let db: Database;
  
  beforeEach(async () => {
    db = await createTestDatabase();
    await seedTestData(db);
  });
  
  afterEach(async () => {
    await cleanupTestData(db);
    await db.end();
  });
  
  it("should save user to database", async () => {
    const user = { name: "John Doe", email: "john@example.com" };
    const savedUser = await userRepository.save(user);
    
    expect(savedUser.id).toBeDefined();
    expect(savedUser.name).toBe(user.name);
    
    // Verify in database
    const dbUser = await db.query("SELECT * FROM users WHERE id = $1", [savedUser.id]);
    expect(dbUser.rows[0]).toEqual(savedUser);
  });
});
```

**Forbidden test patterns:**
```typescript
// ‚ùå BAD: Mock the system under test
jest.mock("./userRepository", () => ({
  save: jest.fn(() => ({ id: 1, name: "Mock User" }))
}));

// ‚ùå BAD: Test fake implementations
test("save user", () => {
  const result = userRepository.save({ name: "John" });
  expect(result.name).toBe("John"); // Tests mock, not real implementation
});
```

## Integration with Existing Tooling

### todo_analyzer.py Features

**Advanced Pattern Detection:**
- **Context-aware analysis** with confidence scoring
- **Language-specific patterns** for Rust, Python, JavaScript, TypeScript, Go, Java, C#, C++, PHP, Ruby, Shell, YAML
- **Code stub detection** beyond just comments
- **Dependency resolution** for staged files
- **Confidence thresholds** to reduce false positives

**Sophisticated Analysis:**
```python
# Context scoring to distinguish documentation from TODOs
def calculate_context_score(self, comment: str, line_num: int, file_path: Path) -> float:
    score = 0.0
    
    # Check for documentation indicators (reduce score)
    if self.is_documentation_comment(comment):
        score -= 0.5
    
    # Check for TODO indicators (increase score)
    if self.has_todo_indicators(comment):
        score += 0.3
    
    # Check if it's in a generated file (reduce score)
    if self.is_generated_file(file_path):
        score -= 0.4
    
    return max(-1.0, min(1.0, score))
```

**Exclusion Patterns:**
```python
# Prevents false positives on legitimate technical terms
exclusion_patterns = [
    r'\bperformance\s+monitoring\b',
    r'\bperformance\s+optimization\b',
    r'\bfallback\s+mechanism\b',
    r'\bbasic\s+authentication\b',
    r'\bmock\s+object\b',  # For testing
    r'\bcurrent\s+implementation\b.*?(uses|provides|supports)',
]
```

### Recommended Usage Patterns

**Development Workflow:**
```bash
# 1. Pre-commit check (fast, staged files only)
python scripts/v3/analysis/todo_analyzer.py --staged-only --min-confidence 0.7 --ci-mode

# 2. Full analysis before major releases
python scripts/v3/analysis/todo_analyzer.py --root . --min-confidence 0.8 --ci-mode

# 3. V3-specific analysis (matches your current focus)
python scripts/v3/analysis/todo_analyzer.py --v3-only --min-confidence 0.8

# 4. Generate reports for review
python scripts/v3/analysis/todo_analyzer.py --root . --min-confidence 0.6 --output-md report.md --output-json analysis.json
```

**CI/CD Integration:**
```yaml
# Different confidence thresholds for different stages
stages:
  - name: "Pre-commit (Staged Files)"
    command: "python scripts/v3/analysis/todo_analyzer.py --staged-only --min-confidence 0.7 --ci-mode"
    
  - name: "Pull Request (V3 Focus)"
    command: "python scripts/v3/analysis/todo_analyzer.py --v3-only --min-confidence 0.8 --ci-mode"
    
  - name: "Release Candidate (Full Analysis)"
    command: "python scripts/v3/analysis/todo_analyzer.py --root . --min-confidence 0.9 --ci-mode"
```

## Quality Metrics

### Implementation Completeness Score

**Using todo_analyzer.py Results:**
```python
# Extract metrics from todo_analyzer.py output
def calculate_completeness_score(analysis_results):
    summary = analysis_results['summary']
    
    total_files = summary['non_ignored_files']
    files_with_todos = summary['files_with_hidden_todos']
    high_conf_todos = summary['high_confidence_todos']
    
    # Completeness score (higher is better)
    completeness_score = 1.0 - (files_with_todos / total_files) if total_files > 0 else 1.0
    
    # Quality score based on confidence levels
    quality_score = 1.0 - (high_conf_todos / total_files) if total_files > 0 else 1.0
    
    return {
        'completeness_score': completeness_score,
        'quality_score': quality_score,
        'files_with_todos': files_with_todos,
        'high_confidence_todos': high_conf_todos,
        'total_files_analyzed': total_files
    }
```

**Anti-Pattern Detection Metrics:**
- **Placeholder Density**: Number of high-confidence TODOs per 1000 lines
- **Stub Implementation Rate**: % of functions with stub patterns detected
- **Temporary Solution Rate**: % of code marked as temporary/workaround
- **Hardcoded Value Rate**: % of magic numbers/strings detected

### Continuous Improvement

**Monthly Audits:**
```bash
# Generate monthly completeness report
python scripts/v3/analysis/todo_analyzer.py \
  --root . \
  --min-confidence 0.6 \
  --output-json monthly-todo-analysis.json \
  --output-md monthly-todo-report.md

# Track trends over time
python scripts/v3/analysis/todo_analyzer.py \
  --v3-only \
  --min-confidence 0.7 \
  --output-json v3-todo-trends.json
```

**Quarterly Reviews:**
- Full implementation audit across entire codebase
- Review integration reality and persistence patterns
- Update quality gates based on project evolution
- Refine detection patterns based on new anti-patterns
- Analyze confidence threshold effectiveness

**Integration with CAWS:**
```bash
# Use CAWS quality monitoring
caws quality-monitor --action=code_edited --files="$(git diff --name-only)"

# Track TODO resolution progress
caws progress-update --criterion-id="TODO-001" --status="completed" --tests-passing=1
```

This rule ensures all implementations are complete, real, and production-ready, leveraging your sophisticated `todo_analyzer.py` tooling to prevent the accumulation of incomplete or fake code that could cause production issues.